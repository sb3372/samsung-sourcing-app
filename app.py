import streamlit as st
from config import SEARCH_CATEGORIES, REGIONS, SYSTEM_PROMPT, LANGUAGE_NAMES
from news_scraper import NewsScraper
import time

st.set_page_config(
    page_title="Samsung ë‰´ìŠ¤ ìˆ˜ì§‘ê¸°",
    page_icon="ğŸ“°",
    layout="wide",
)

st.title("ğŸ“° Samsung êµ­ì œ ì¡°ë‹¬ì„¼í„° ë‰´ìŠ¤ ìˆ˜ì§‘ê¸°")
st.markdown("---")

# ì„¸ì…˜ ì´ˆê¸°í™”
if "scraper" not in st.session_state:
    st.session_state.scraper = None
if "articles" not in st.session_state:
    st.session_state.articles = []
if "api_key_set" not in st.session_state:
    st.session_state.api_key_set = False

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    
    # API í‚¤ ì…ë ¥
    api_key = st.text_input(
        "ğŸ”‘ Gemini API í‚¤",
        type="password",
        help="https://aistudio.google.com/app/apikeyì—ì„œ ë°œê¸‰"
    )
    
    if api_key:
        st.session_state.api_key_set = True
        if st.session_state.scraper is None:
            st.session_state.scraper = NewsScraper(api_key, SYSTEM_PROMPT)
            st.success("âœ… API í‚¤ ì„¤ì • ì™„ë£Œ!")
    else:
        st.session_state.api_key_set = False
        st.warning("âš ï¸ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”")
    
    st.markdown("---")
    
    # ì¹´í…Œê³ ë¦¬ ì„ íƒ
    st.header("ğŸ“‚ ì¹´í…Œê³ ë¦¬ ì„ íƒ")
    selected_categories = []
    
    for category_name in SEARCH_CATEGORIES.keys():
        if st.checkbox(category_name, value=True):
            selected_categories.append(category_name)
    
    st.markdown("---")
    
    # ìƒˆë¡œ ë¶ˆëŸ¬ì˜¤ê¸° ë²„íŠ¼
    if st.button("ğŸ” ìƒˆë¡œ ë¶ˆëŸ¬ì˜¤ê¸°", use_container_width=True, type="primary"):
        if not st.session_state.api_key_set:
            st.error("âŒ API í‚¤ë¥¼ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”!")
        elif not selected_categories:
            st.error("âŒ ìµœì†Œ 1ê°œ ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”!")
        else:
            st.session_state.articles = []
            
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            total_tasks = len(selected_categories) * len(REGIONS)
            current_task = 0
            
            for category_name in selected_categories:
                category_data = SEARCH_CATEGORIES[category_name]
                
                for region_name, region_data in REGIONS.items():
                    current_task += 1
                    progress = current_task / total_tasks
                    progress_bar.progress(progress)
                    status_text.text(f"ìˆ˜ì§‘ ì¤‘... {category_name} - {region_name}")
                    
                    for keyword in category_data["keywords"]:
                        try:
                            articles = st.session_state.scraper.fetch_rss_feed(
                                keyword,
                                region_data["lang"],
                                region_data["region"]
                            )
                            
                            for article in articles:
                                processed = st.session_state.scraper.process_article(article)
                                if processed:
                                    processed["category"] = category_name
                                    st.session_state.articles.append(processed)
                        
                        except Exception as e:
                            print(f"ì˜¤ë¥˜: {e}")
                    
                    time.sleep(0.5)
            
            progress_bar.empty()
            status_text.empty()
            
            if st.session_state.articles:
                st.success(f"âœ… ìˆ˜ì§‘ ì™„ë£Œ! {len(st.session_state.articles)}ê°œ ê¸°ì‚¬")
            else:
                st.warning("âš ï¸ ìˆ˜ì§‘ëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ë©”ì¸ ì½˜í…ì¸ 
if st.session_state.articles:
    st.header(f"ğŸ“Š ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ({len(st.session_state.articles)}ê°œ)")
    st.markdown("---")
    
    for idx, article in enumerate(st.session_state.articles):
            for idx, article in enumerate(st.session_state.articles):
        with st.container():  # border=True ì œê±°
            # í—¤ë”
            col1, col2, col3 = st.columns([1, 2, 1])
            
            with col1:
                st.caption(f"ğŸ“‚ {article['category']}")
            
            with col2:
                st.caption(f"ğŸŒ {article['region']} | ğŸ—£ï¸ {LANGUAGE_NAMES.get(article['language'], article['language'])}")
            
            with col3:
                if st.button("ğŸ”„", key=f"refresh_{idx}"):
                    st.info("ì¬ë¶„ì„ ê¸°ëŠ¥ì€ ì¶”í›„ ì¶”ê°€ë©ë‹ˆë‹¤.")
            
            st.divider()  # êµ¬ë¶„ì„  ì¶”ê°€
            
            # ì œëª©
            st.subheader(article["title"])
            
            # ìš”ì•½
            st.markdown("### ğŸ“ ìš”ì•½")
            st.markdown(article["summary"])
            
            # ì†ŒìŠ¤ ì •ë³´
            col1, col2, col3 = st.columns(3)
            with col1:
                st.caption(f"**ì¶œì²˜:** {article['source']}")
            with col2:
                st.caption(f"**ë°œí–‰ì¼:** {article['published'][:10]}")
            with col3:
                st.markdown(f"[ğŸ”— ì›ë³¸](https://news.google.com/search?q=cache:{article['link']})")

else:
    if st.session_state.api_key_set:
        st.info("ğŸ“‹ 'ìƒˆë¡œ ë¶ˆëŸ¬ì˜¤ê¸°'ë¥¼ í´ë¦­í•˜ì—¬ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ì„¸ìš”.")
    else:
        st.warning("âš ï¸ ë¨¼ì € API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
