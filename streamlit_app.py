import streamlit as st
from tavily import TavilyClient
from datetime import datetime, timedelta
import os
import json
import hashlib
from collections import defaultdict
import re

# ===== PAGE CONFIGURATION =====
st.set_page_config(
    page_title="Samsung Strategic Sourcing Agent",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ===== CUSTOM CSS FOR BETTER DESIGN =====
st.markdown("""
<style>
    :root {
        --samsung-blue: #1428a0;
        --samsung-accent: #0066ff;
        --dark-bg: #0f1419;
        --card-bg: #1a1f2e;
        --text-primary: #ffffff;
        --text-secondary: #b0b8c1;
        --success-color: #10b981;
        --warning-color: #f59e0b;
    }
    
    .main {
        background: linear-gradient(135deg, #0f1419 0%, #1a1f2e 100%);
    }
    
    .header-container {
        background: linear-gradient(90deg, #1428a0 0%, #0066ff 100%);
        padding: 2rem;
        border-radius: 10px;
        margin-bottom: 2rem;
        box-shadow: 0 4px 15px rgba(20, 40, 160, 0.3);
    }
    
    .header-container h1 {
        color: white;
        margin: 0;
        font-size: 2.5rem;
        font-weight: 700;
    }
    
    .header-container p {
        color: rgba(255,255,255,0.9);
        margin: 0.5rem 0 0 0;
        font-size: 1rem;
    }
    
    .stButton>button {
        background: linear-gradient(90deg, #1428a0 0%, #0066ff 100%);
        color: white;
        border: none;
        font-weight: 600;
        padding: 0.6rem 1.5rem;
        border-radius: 6px;
        transition: all 0.3s ease;
    }
    
    .stButton>button:hover {
        box-shadow: 0 4px 12px rgba(0, 102, 255, 0.4);
    }
    
    [data-testid="stSidebar"] {
        background: #1a1f2e;
    }
    
    [data-testid="metric-container"] {
        background: #1a1f2e;
        border-left: 3px solid #0066ff;
    }
    
    a {
        color: #0066ff !important;
        text-decoration: none;
    }
    
    a:hover {
        text-decoration: underline;
    }
    
    hr {
        border: none;
        border-top: 1px solid rgba(0, 102, 255, 0.2);
        margin: 1.5rem 0;
    }
</style>
""", unsafe_allow_html=True)

# ===== CONFIGURATION =====
LANGUAGES = {
    "English": "en",
    "German": "de",
    "French": "fr",
    "Spanish": "es",
    "Italian": "it",
    "Polish": "pl",
    "Dutch": "nl",
    "Danish": "da",
    "Norwegian": "no",
    "Swedish": "sv"
}

CATEGORIES = {
    "ì¡°ë‹¬ ë° ì†Œì¬": {
        "emoji": "ğŸ’°",
        "queries": {
            "en": "semiconductor price volatility Europe 2024 2025",
            "de": "Halbleiter Preise Europa",
            "fr": "prix semiconducteur Europe",
            "es": "precios semiconductores Europa",
            "it": "prezzi semiconduttori Europa",
            "pl": "ceny pÃ³Å‚przewodnikÃ³w Europa",
            "nl": "prijzen semiconductors Europa",
            "da": "priser halvledere Europa",
            "no": "priser halvledere Europa",
            "sv": "priser halvledare Europa"
        },
    },
    "ê³µê¸‰ë§ ë° ë¬¼ë¥˜": {
        "emoji": "ğŸš¢",
        "queries": {
            "en": "logistics disruption Europe port strikes 2024",
            "de": "Logistik StÃ¶rungen Europa Hafenstreiks",
            "fr": "perturbations logistiques Europe grÃ¨ves portuaires",
            "es": "disrupciones logÃ­sticas Europa huelgas portuarias",
            "it": "interruzioni logistiche Europa scioperi portuali",
            "pl": "zakÅ‚Ã³cenia logistyczne Europa strajki portowe",
            "nl": "logistieke verstoringen Europa havenstakingen",
            "da": "logistiske forstyrrelser Europa havnestrejker",
            "no": "logistiske forstyrrelser Europa havnestreiker",
            "sv": "logistiska stÃ¶rningar Europa hamnstrejker"
        },
    },
    "EU ê·œì œ ë° ì¤€ìˆ˜": {
        "emoji": "âš–ï¸",
        "queries": {
            "en": "EU AI Act CRA regulation electronics 2024",
            "de": "EU KI Gesetz CRA Verordnung Elektronik",
            "fr": "Loi IA UE CRA rÃ¨glement Ã©lectronique",
            "es": "Ley IA UE CRA reglamento electrÃ³nico",
            "it": "Legge IA UE CRA regolamento elettronico",
            "pl": "Ustawa AI UE CRA regulacja elektronika",
            "nl": "EU AI wet CRA regelgeving elektronica",
            "da": "EU AI lov CRA regulering elektronik",
            "no": "EU AI lov CRA regulering elektronikk",
            "sv": "EU AI lag CRA regulering elektronik"
        },
    },
    "í˜ì‹  ë° ìƒíƒœê³„": {
        "emoji": "ğŸš€",
        "queries": {
            "en": "European startups 6G robotics AI innovation 2024",
            "de": "EuropÃ¤ische Startups 6G Robotik AI Innovation",
            "fr": "startups europÃ©ens 6G robotique IA innovation",
            "es": "startups europeos 6G robÃ³tica IA innovaciÃ³n",
            "it": "startup europei 6G robotica IA innovazione",
            "pl": "startupy europejskie 6G robotyka AI innowacja",
            "nl": "Europese startups 6G robotica AI innovatie",
            "da": "EuropÃ¦iske startups 6G robotik AI innovation",
            "no": "Europeiske startups 6G robotikk AI innovasjon",
            "sv": "Europeiska startups 6G robotik AI innovation"
        },
    },
    "Samsung í¬íŠ¸í´ë¦¬ì˜¤": {
        "emoji": "ğŸ“±",
        "queries": {
            "en": "Samsung Europe technology innovation 2024 2025",
            "de": "Samsung Europa Technologie Innovation",
            "fr": "Samsung Europe technologie innovation",
            "es": "Samsung Europa tecnologÃ­a innovaciÃ³n",
            "it": "Samsung Europa tecnologia innovazione",
            "pl": "Samsung Europa technologia innowacja",
            "nl": "Samsung Europa technologie innovatie",
            "da": "Samsung Europa teknologi innovation",
            "no": "Samsung Europa teknologi innovasjon",
            "sv": "Samsung Europa teknik innovation"
        },
    }
}

MAX_ARTICLE_AGE_DAYS = 7
MAX_SEARCH_AGE_DAYS = 30
MAX_TOTAL_ARTICLES = 10
MAX_PER_CATEGORY = 2

# ===== FILE MANAGEMENT =====
HISTORY_FILE = "article_history.json"

def load_history():
    """Load article history with metadata"""
    if not os.path.exists(HISTORY_FILE):
        return {
            "articles": {},
            "content_hashes": set(),
            "last_updated": None
        }
    try:
        with open(HISTORY_FILE, "r", encoding="utf-8") as f:
            data = json.load(f)
            data["content_hashes"] = set(data.get("content_hashes", []))
            return data
    except:
        return {"articles": {}, "content_hashes": set(), "last_updated": None}

def save_history(history):
    """Save article history with metadata"""
    save_data = history.copy()
    save_data["content_hashes"] = list(history["content_hashes"])
    with open(HISTORY_FILE, "w", encoding="utf-8") as f:
        json.dump(save_data, f, ensure_ascii=False, indent=2)

def get_content_hash(title, content):
    """Generate hash of article content for deduplication"""
    text = f"{title}{content}".lower()
    text = re.sub(r'\s+', ' ', text)
    return hashlib.md5(text.encode()).hexdigest()

def is_duplicate(title, content, history):
    """Check if article is duplicate based on content hash"""
    content_hash = get_content_hash(title, content)
    return content_hash in history["content_hashes"]

def add_to_history(url, title, content, category, language):
    """Add article to history"""
    history = load_history()
    content_hash = get_content_hash(title, content)
    
    history["articles"][url] = {
        "title": title,
        "category": category,
        "language": language,
        "date_added": datetime.now().isoformat(),
        "content_preview": content[:300]
    }
    history["content_hashes"].add(content_hash)
    history["last_updated"] = datetime.now().isoformat()
    
    save_history(history)

# ===== FREE TRANSLATION USING GOOGLE TRANSLATE =====
@st.cache_data
def translate_to_korean_cached(text):
    """Translate text to Korean with caching"""
    try:
        from google_trans_new import google_translator
        translator = google_translator()
        result = translator.translate(text, lang_src='en', lang_tgt='ko')
        return result
    except Exception as e:
        return text

# ===== SMART CONTENT SUMMARIZATION =====
def smart_summarize_content(title, content):
    """
    Intelligently summarize content by:
    1. Cleaning and processing text
    2. Finding main sentences with important information
    3. Extracting exactly 3 meaningful summary points
    """
    
    # Clean content
    content = content.replace('\n', ' ').replace('\r', ' ')
    content = re.sub(r'\s+', ' ', content).strip()
    
    # Split into sentences
    sentences = re.split(r'(?<=[.!?])\s+', content)
    sentences = [s.strip() for s in sentences if len(s.strip()) > 15 and len(s.strip()) < 300]
    
    if not sentences:
        return [
            "ê¸°ì‚¬ ë‚´ìš©ì„ ìƒì„¸íˆ ì½ê¸° ìœ„í•´ ì „ì²´ ê¸°ì‚¬ ë§í¬ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.",
            "ì£¼ìš” ì •ë³´ ë° í†µê³„ëŠ” ì›ë¬¸ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            "ë” ìì„¸í•œ ë‚´ìš©ì€ ì¶œì²˜ ê¸°ì‚¬ë¥¼ í†µí•´ í™•ì¸í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤."
        ]
    
    # Score sentences based on keywords
    def score_sentence(sent):
        score = 0
        # Prefer sentences with numbers
        if re.search(r'\d+', sent):
            score += 3
        # Prefer longer sentences with more info
        if len(sent.split()) > 8:
            score += 2
        # Prefer sentences with important keywords
        keywords = ['growth', 'increase', 'decrease', 'change', 'innovation', 'technology', 'market', 'price', 'supply', 'demand', 'new', 'launch', 'partnership', 'agreement']
        for keyword in keywords:
            if keyword.lower() in sent.lower():
                score += 1
        return score
    
    # Score all sentences
    scored_sentences = [(sent, score_sentence(sent)) for sent in sentences]
    scored_sentences = sorted(scored_sentences, key=lambda x: x[1], reverse=True)
    
    # Get top 3 unique sentences, maintain order from original
    top_3 = scored_sentences[:3]
    
    # Sort back to original order
    top_3_dict = {sent: idx for idx, (sent, _) in enumerate(scored_sentences[:3])}
    final_sentences = []
    for idx, sent in enumerate(sentences):
        if sent in top_3_dict:
            final_sentences.append(sent)
        if len(final_sentences) == 3:
            break
    
    # Fallback if we couldn't get 3
    if len(final_sentences) < 3:
        final_sentences = [sent for sent, _ in top_3[:3]]
    
    return final_sentences[:3]

# ===== MULTI-LANGUAGE SEARCH =====
def perform_multilingual_search(category_config, category_name, tavily_client, history, max_results=3, debug_info=None):
    """Perform searches across multiple languages"""
    
    all_results = []
    seen_urls = set()
    search_attempts = []
    
    for lang_name, lang_code in LANGUAGES.items():
        if len(all_results) >= MAX_PER_CATEGORY:
            break
            
        query = category_config["queries"].get(lang_code, category_config["queries"]["en"])
        
        try:
            results = tavily_client.search(
                query=query,
                search_depth="advanced",
                max_results=max_results,
                include_raw_content=True
            )
            
            search_attempts.append({
                "language": lang_name,
                "query": query,
                "results_count": len(results.get('results', []))
            })
            
            for res in results.get('results', []):
                if len(all_results) >= MAX_PER_CATEGORY:
                    break
                    
                url = res.get('url')
                title = res.get('title', 'No title')
                content = res.get('content', '')
                
                if url in seen_urls or url in history["articles"]:
                    continue
                
                if len(content) < 50:
                    continue
                
                if is_duplicate(title, content, history):
                    continue
                
                seen_urls.add(url)
                
                all_results.append({
                    "url": url,
                    "title": title,
                    "content": content,
                    "language": lang_name,
                    "lang_code": lang_code,
                    "raw_content": res.get('raw_content', content)[:500]
                })
        
        except Exception as e:
            search_attempts.append({
                "language": lang_name,
                "query": query,
                "error": str(e)
            })
    
    if debug_info is not None:
        debug_info.append({
            "category": category_name,
            "total_results": len(all_results),
            "search_attempts": search_attempts
        })
    
    return all_results

# ===== MAIN UI =====
st.markdown("""
<div class="header-container">
    <h1>ğŸ›¡ï¸ Samsung ìœ ëŸ½ ì¡°ë‹¬ ì„¼í„° ì „ëµ ì¸í…”ë¦¬ì „ìŠ¤</h1>
    <p>ì „ëµ ì •ë³´ ëŒ€ì‹œë³´ë“œ â€¢ ì¼ì¼ ìë™í™” ë¦¬í¬íŠ¸</p>
</div>
""", unsafe_allow_html=True)

# Sidebar
st.sidebar.header("âš™ï¸ ì„¤ì •")
tavily_key = st.sidebar.text_input("Tavily API Key", type="password", help="Tavily API í‚¤ ì…ë ¥")

# ë””ë²„ê·¸ ëª¨ë“œ
debug_mode = st.sidebar.checkbox("ğŸ› ë””ë²„ê·¸ ëª¨ë“œ", value=False)

# History stats
history = load_history()
st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ“Š íˆìŠ¤í† ë¦¬ ìƒíƒœ")

col1, col2 = st.sidebar.columns(2)
col1.metric("ì¶”ì ëœ ê¸°ì‚¬", len(history["articles"]))
col2.metric("ê³ ìœ  ì½˜í…ì¸ ", len(history["content_hashes"]))

if history.get("last_updated"):
    last_update = datetime.fromisoformat(history["last_updated"])
    st.sidebar.caption(f"ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {last_update.strftime('%Y-%m-%d %H:%M')}")

if st.sidebar.button("ğŸ—‘ï¸ íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”", use_container_width=True):
    if os.path.exists(HISTORY_FILE):
        os.remove(HISTORY_FILE)
    st.rerun()

# ===== MAIN REPORT BUTTON =====
st.markdown("---")

col_button1, col_button2 = st.columns([2, 1])
with col_button1:
    run_report = st.button("ğŸš€ ì „ëµ ì¸í…”ë¦¬ì „ìŠ¤ ë¦¬í¬íŠ¸ ìƒì„±", use_container_width=True, key="run_report")

with col_button2:
    if st.button("â„¹ï¸ ì†Œê°œ", use_container_width=True):
        st.info("""
        **Samsung ì „ëµ ì¡°ë‹¬ ì—ì´ì „íŠ¸**
        
        ì´ ìë™í™” ì‹œìŠ¤í…œì€ ìœ ëŸ½ ë‰´ìŠ¤ë¥¼ 10ê°œ ì–¸ì–´ë¡œ ë§¤ì¼ ìŠ¤ìº”í•˜ì—¬ ë‹¤ìŒì„ ì‹ë³„í•©ë‹ˆë‹¤:
        â€¢ ê°€ê²© ë³€ë™ì„± & ê³µê¸‰ ìœ„í—˜
        â€¢ ë¬¼ë¥˜ ì¤‘ë‹¨
        â€¢ EU ê·œì œ ì—…ë°ì´íŠ¸
        â€¢ í˜ì‹  ê¸°íšŒ
        â€¢ Samsung í¬íŠ¸í´ë¦¬ì˜¤ ê°œë°œ
        """)

# ===== RUN REPORT LOGIC =====
if run_report:
    if not tavily_key:
        st.error("âŒ ì‚¬ì´ë“œë°”ì— Tavily API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    else:
        client = TavilyClient(api_key=tavily_key)
        history = load_history()
        
        # Progress tracking
        progress_container = st.container()
        with progress_container:
            progress_bar = st.progress(0)
            status_text = st.empty()
        
        all_articles = []
        articles_by_category = {}
        debug_info = [] if debug_mode else None
        
        # Search all categories
        for idx, (cat_name, cat_config) in enumerate(CATEGORIES.items()):
            status_text.text(f"ğŸ” {cat_name} ê²€ìƒ‰ ì¤‘...")
            
            results = perform_multilingual_search(
                cat_config, 
                cat_name, 
                client, 
                history,
                max_results=2,
                debug_info=debug_info
            )
            
            if results:
                articles_by_category[cat_name] = results
                all_articles.extend(results)
            
            progress_bar.progress((idx + 1) / len(CATEGORIES))
        
        # Limit to max 10 articles
        all_articles = all_articles[:MAX_TOTAL_ARTICLES]
        
        # Clear progress indicators
        progress_bar.empty()
        status_text.empty()
        
        # Debug info
        if debug_mode and debug_info:
            st.markdown("### ğŸ› ë””ë²„ê·¸ ì •ë³´")
            for info in debug_info:
                with st.expander(f"{info['category']} - {info['total_results']}ê°œ ê¸°ì‚¬ ë°œê²¬"):
                    for attempt in info['search_attempts']:
                        st.write(f"**{attempt['language']}**: {attempt.get('results_count', 0)} ê²°ê³¼")
                        st.code(attempt['query'])
                        if 'error' in attempt:
                            st.error(f"Error: {attempt['error']}")
        
        # Summary stats
        st.markdown("---")
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("ğŸ” ìƒˆ ê¸°ì‚¬ ë°œê²¬", len(all_articles))
        col2.metric("ğŸ“‚ ê²€ìƒ‰ëœ ì¹´í…Œê³ ë¦¬", len(articles_by_category))
        col3.metric("ğŸ’¾ ì´ ì¶”ì ëœ ê¸°ì‚¬", len(history["articles"]))
        col4.metric("ğŸŒ ê²€ìƒ‰í•œ ì–¸ì–´", len(LANGUAGES))
        
        st.markdown("---")
        
        # Display articles by category
        if all_articles:
            article_count = 0
            
            for cat_name, articles in articles_by_category.items():
                if article_count >= MAX_TOTAL_ARTICLES:
                    break
                
                cat_emoji = CATEGORIES[cat_name]["emoji"]
                
                # Category header
                st.markdown(f"### {cat_emoji} {cat_name}")
                st.markdown(f"*{len(articles)}ê°œì˜ ìƒˆë¡œìš´ ê¸°ì‚¬*")
                
                # Articles in this category
                for article in articles:
                    if article_count >= MAX_TOTAL_ARTICLES:
                        break
                    
                    article_count += 1
                    
                    # Smart summarize content
                    with st.spinner(f"ğŸ“ ê¸°ì‚¬ {article_count} ë¶„ì„ ì¤‘..."):
                        summary_points = smart_summarize_content(article['title'], article['content'])
                        
                        # Translate title to Korean
                        try:
                            title_kr = translate_to_korean_cached(article['title'])
                        except Exception as e:
                            title_kr = article['title']
                    
                    # Article display
                    st.markdown(f"#### ğŸ“° {article_count}. {title_kr}")
                    col_lang, col_cat = st.columns([1, 1])
                    with col_lang:
                        st.caption(f"ğŸŒ {article['language']}")
                    with col_cat:
                        st.caption(f"ğŸ“‚ {cat_name}")
                    
                    # Summary with 3 key points from article
                    st.markdown("**â–¡**")
                    st.markdown(f"- {summary_points[0]}")
                    st.markdown(f"- {summary_points[1]}")
                    st.markdown(f"- {summary_points[2]}")
                    
                    # Action buttons
                    col1, col2, col3 = st.columns([2, 1, 1])
                    
                    with col1:
                        st.markdown(f"[ğŸ“– ì „ì²´ ê¸°ì‚¬ ì½ê¸°]({article['url']})")
                    
                    with col2:
                        if st.button("âœ… ì½ìŒ í‘œì‹œ", key=f"read_{article['url']}", use_container_width=True):
                            add_to_history(
                                article['url'],
                                article['title'],
                                article['content'],
                                cat_name,
                                article['language']
                            )
                            st.success("íˆìŠ¤í† ë¦¬ì— ì¶”ê°€!")
                    
                    with col3:
                        if st.button("ğŸ”— URL ë³µì‚¬", key=f"copy_{article['url']}", use_container_width=True):
                            st.code(article['url'], language="text")
                    
                    st.divider()
            
            # Final stats
            st.markdown("### ğŸ“Š ë¦¬í¬íŠ¸ ìš”ì•½")
            summary_col1, summary_col2, summary_col3 = st.columns(3)
            
            with summary_col1:
                st.metric("âœ… ì™„ë£Œ", "ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ")
            
            with summary_col2:
                st.metric("ğŸ†• ìƒˆ ê¸°ì‚¬", len(all_articles))
            
            with summary_col3:
                st.metric("ğŸ“ˆ ë°ì´í„°ë² ì´ìŠ¤", len(history["articles"]))
        
        else:
            st.warning("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ëª‡ ê°€ì§€ í™•ì¸ì‚¬í•­:")
            st.markdown("""
            1. **Tavily API í‚¤ í™•ì¸**: API í‚¤ê°€ ìœ íš¨í•œì§€ í™•ì¸í•˜ì„¸ìš”.
            2. **ê²€ìƒ‰ ì¿¼ë¦¬**: ë” ê°„ë‹¨í•œ ê²€ìƒ‰ì–´ë¡œ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.
            3. **ë°ì´í„° ê°€ìš©ì„±**: Tavilyì— í•´ë‹¹ ì§€ì—­ì˜ ê¸°ì‚¬ê°€ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            4. **ë””ë²„ê·¸ ëª¨ë“œ**: ì‚¬ì´ë“œë°”ì—ì„œ "ë””ë²„ê·¸ ëª¨ë“œ"ë¥¼ ì¼œê³  ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.
            """)
            
            if debug_mode:
                st.info("ğŸ’¡ ë””ë²„ê·¸ ì •ë³´ëŠ” ìœ„ì˜ 'ë””ë²„ê·¸ ì •ë³´' ì„¹ì…˜ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
