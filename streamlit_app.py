import streamlit as st
from tavily import TavilyClient
from datetime import datetime, timedelta
import os
import json
import hashlib
from collections import defaultdict
import re
import requests

# ===== PAGE CONFIGURATION =====
st.set_page_config(
    page_title="Samsung Strategic Sourcing Agent",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ===== CUSTOM CSS =====
st.markdown("""
<style>
    :root {
        --samsung-blue: #1428a0;
        --samsung-accent: #0066ff;
        --dark-bg: #0f1419;
        --card-bg: #1a1f2e;
        --text-primary: #ffffff;
        --text-secondary: #b0b8c1;
    }
    
    .main {
        background: linear-gradient(135deg, #0f1419 0%, #1a1f2e 100%);
    }
    
    .header-container {
        background: linear-gradient(90deg, #1428a0 0%, #0066ff 100%);
        padding: 2rem;
        border-radius: 10px;
        margin-bottom: 2rem;
        box-shadow: 0 4px 15px rgba(20, 40, 160, 0.3);
    }
    
    .header-container h1 {
        color: white;
        margin: 0;
        font-size: 2.5rem;
        font-weight: 700;
    }
    
    .header-container p {
        color: rgba(255,255,255,0.9);
        margin: 0.5rem 0 0 0;
        font-size: 1rem;
    }
    
    .stButton>button {
        background: linear-gradient(90deg, #1428a0 0%, #0066ff 100%);
        color: white;
        border: none;
        font-weight: 600;
        padding: 0.6rem 1.5rem;
        border-radius: 6px;
        transition: all 0.3s ease;
    }
    
    .stButton>button:hover {
        box-shadow: 0 4px 12px rgba(0, 102, 255, 0.4);
    }
    
    [data-testid="stSidebar"] {
        background: #1a1f2e;
    }
    
    [data-testid="metric-container"] {
        background: #1a1f2e;
        border-left: 3px solid #0066ff;
    }
    
    a {
        color: #0066ff !important;
        text-decoration: none;
    }
</style>
""", unsafe_allow_html=True)

# ===== CONFIGURATION =====
LANGUAGES = {
    "English": "en",
    "German": "de",
    "French": "fr",
    "Spanish": "es",
    "Italian": "it",
    "Polish": "pl",
    "Dutch": "nl",
    "Danish": "da",
    "Norwegian": "no",
    "Swedish": "sv"
}

CATEGORIES = {
    "ì¡°ë‹¬ ë° ì†Œì¬": {
        "emoji": "ğŸ’°",
        "queries": {
            "en": "semiconductor price volatility Europe 2024 2025",
            "de": "Halbleiter Preise Europa",
            "fr": "prix semiconducteur Europe",
            "es": "precios semiconductores Europa",
            "it": "prezzi semiconduttori Europa",
            "pl": "ceny pÃ³Å‚przewodnikÃ³w Europa",
            "nl": "prijzen semiconductors Europa",
            "da": "priser halvledere Europa",
            "no": "priser halvledere Europa",
            "sv": "priser halvledare Europa"
        },
    },
    "ê³µê¸‰ë§ ë° ë¬¼ë¥˜": {
        "emoji": "ğŸš¢",
        "queries": {
            "en": "logistics disruption Europe port strikes 2024",
            "de": "Logistik StÃ¶rungen Europa Hafenstreiks",
            "fr": "perturbations logistiques Europe grÃ¨ves portuaires",
            "es": "disrupciones logÃ­sticas Europa huelgas portuarias",
            "it": "interruzioni logistiche Europa scioperi portuali",
            "pl": "zakÅ‚Ã³cenia logistyczne Europa strajki portowe",
            "nl": "logistieke verstoringen Europa havenstakingen",
            "da": "logistiske forstyrrelser Europa havnestrejker",
            "no": "logistiske forstyrrelser Europa havnestreiker",
            "sv": "logistiska stÃ¶rningar Europa hamnstrejker"
        },
    },
    "EU ê·œì œ ë° ì¤€ìˆ˜": {
        "emoji": "âš–ï¸",
        "queries": {
            "en": "EU AI Act CRA regulation electronics 2024",
            "de": "EU KI Gesetz CRA Verordnung Elektronik",
            "fr": "Loi IA UE CRA rÃ¨glement Ã©lectronique",
            "es": "Ley IA UE CRA reglamento electrÃ³nico",
            "it": "Legge IA UE CRA regolamento elettronico",
            "pl": "Ustawa AI UE CRA regulacja elektronika",
            "nl": "EU AI wet CRA regelgeving elektronica",
            "da": "EU AI lov CRA regulering elektronik",
            "no": "EU AI lov CRA regulering elektronikk",
            "sv": "EU AI lag CRA regulering elektronik"
        },
    },
    "í˜ì‹  ë° ìƒíƒœê³„": {
        "emoji": "ğŸš€",
        "queries": {
            "en": "European startups 6G robotics AI innovation 2024",
            "de": "EuropÃ¤ische Startups 6G Robotik AI Innovation",
            "fr": "startups europÃ©ens 6G robotique IA innovation",
            "es": "startups europeos 6G robÃ³tica IA innovaciÃ³n",
            "it": "startup europei 6G robotica IA innovazione",
            "pl": "startupy europejskie 6G robotyka AI innowacja",
            "nl": "Europese startups 6G robotica AI innovatie",
            "da": "EuropÃ¦iske startups 6G robotik AI innovation",
            "no": "Europeiske startups 6G robotikk AI innovasjon",
            "sv": "Europeiska startups 6G robotik AI innovation"
        },
    },
    "Samsung í¬íŠ¸í´ë¦¬ì˜¤": {
        "emoji": "ğŸ“±",
        "queries": {
            "en": "Samsung Europe technology innovation 2024 2025",
            "de": "Samsung Europa Technologie Innovation",
            "fr": "Samsung Europe technologie innovation",
            "es": "Samsung Europa tecnologÃ­a innovaciÃ³n",
            "it": "Samsung Europa tecnologia innovazione",
            "pl": "Samsung Europa technologia innowacja",
            "nl": "Samsung Europa technologie innovatie",
            "da": "Samsung Europa teknologi innovation",
            "no": "Samsung Europa teknologi innovasjon",
            "sv": "Samsung Europa teknik innovation"
        },
    }
}

MAX_TOTAL_ARTICLES = 10
MAX_PER_CATEGORY = 2
HISTORY_FILE = "article_history.json"

# ===== FILE MANAGEMENT =====
def load_history():
    if not os.path.exists(HISTORY_FILE):
        return {"articles": {}, "content_hashes": set(), "last_updated": None}
    try:
        with open(HISTORY_FILE, "r", encoding="utf-8") as f:
            data = json.load(f)
            data["content_hashes"] = set(data.get("content_hashes", []))
            return data
    except:
        return {"articles": {}, "content_hashes": set(), "last_updated": None}

def save_history(history):
    save_data = history.copy()
    save_data["content_hashes"] = list(history["content_hashes"])
    with open(HISTORY_FILE, "w", encoding="utf-8") as f:
        json.dump(save_data, f, ensure_ascii=False, indent=2)

def get_content_hash(title, content):
    text = f"{title}{content}".lower()
    text = re.sub(r'\s+', ' ', text)
    return hashlib.md5(text.encode()).hexdigest()

def is_duplicate(title, content, history):
    content_hash = get_content_hash(title, content)
    return content_hash in history["content_hashes"]

def add_to_history(url, title, content, category, language):
    history = load_history()
    content_hash = get_content_hash(title, content)
    history["articles"][url] = {
        "title": title,
        "category": category,
        "language": language,
        "date_added": datetime.now().isoformat(),
        "content_preview": content[:300]
    }
    history["content_hashes"].add(content_hash)
    history["last_updated"] = datetime.now().isoformat()
    save_history(history)

# ===== TRANSLATION =====
@st.cache_data
def translate_to_korean_cached(text):
    try:
        from google_trans_new import google_translator
        translator = google_translator()
        result = translator.translate(text, lang_src='en', lang_tgt='ko')
        return result
    except:
        return text

# ===== SMART SUMMARIZATION WITH LLM =====
def summarize_with_groq(title, content, cohere_api_key):
    """
    Use Cohere API to generate proper Korean summary
    Format: â–¡ ì œëª©
            - í•µì‹¬í¬ì¸íŠ¸1
            Â·ì„¸ë¶€ì‚¬í•­
            - í•µì‹¬í¬ì¸íŠ¸2
            Â·ì„¸ë¶€ì‚¬í•­
    """
    try:
        headers = {
            "Authorization": f"Bearer {cohere_api_key}",
            "Content-Type": "application/json"
        }
        
        prompt = f"""ê¸°ì‚¬ ì œëª©: {title}

ê¸°ì‚¬ ë‚´ìš©: {content[:2000]}

ìœ„ ê¸°ì‚¬ë¥¼ ë‹¤ìŒ í•œêµ­ì–´ í¬ë§·ìœ¼ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”. ê¸°ì‚¬ ë‚´ìš©ë§Œ ìš”ì•½í•˜ê³ , ì „ëµì  ë¶„ì„ì€ í•˜ì§€ ë§ˆì„¸ìš”.

í¬ë§·:
â–¡ [ê¸°ì‚¬ ì œëª©ì„ í•œêµ­ì–´ë¡œ ë²ˆì—­]1)
- [í•µì‹¬ í¬ì¸íŠ¸ 1 (êµ¬ì²´ì ì¸ ìˆ«ìë‚˜ ì‚¬ì‹¤)]
Â·[í•µì‹¬ í¬ì¸íŠ¸ 1ì˜ ì„¸ë¶€ ì„¤ëª… (í•œ ë¬¸ì¥)]
- [í•µì‹¬ í¬ì¸íŠ¸ 2 (ë‹¤ë¥¸ ê´€ì ì˜ ì‚¬ì‹¤)]
Â·[í•µì‹¬ í¬ì¸íŠ¸ 2ì˜ ì„¸ë¶€ ì„¤ëª… (í•œ ë¬¸ì¥)]
- [í•µì‹¬ í¬ì¸íŠ¸ 3 (ì˜í–¥ ë˜ëŠ” ê²°ê³¼)]
Â·[í•µì‹¬ í¬ì¸íŠ¸ 3ì˜ ì„¸ë¶€ ì„¤ëª… (í•œ ë¬¸ì¥)]

ì˜ˆì‹œ:
â–¡ ASML, EUV ê´‘ì› ì¶œê²© 1,000W ëŒíŒŒ... ë°˜ë„ì²´ ìƒì‚°ì„± 50% í–¥ìƒ ì˜ˆê³ 1)
- ê¸°ì¡´ 600W ìˆ˜ì¤€ EUV ê´‘ì› ì¶œë ¥ì„ 1,000Wê¹Œì§€ ëŒì–´ì˜¬ë¦¬ëŠ” ë° ì„±ê³µ
Â·ì•¡ì²´ ì£¼ì„(Molten Tin) ë°©ìš¸ íˆ¬ì‚¬ ì†ë„ 2ë°°ë¡œ í–¥ìƒ
- ì¶œë ¥ ê°•í™”ë¡œ, í˜„ì¬ ì‹œê°„ë‹¹ 220ì¥ '30ë…„ 330ì¥ ìˆ˜ì¤€ìœ¼ë¡œ í™•ëŒ€ ì „ë§
Â·ë ˆì´ì € í„ìŠ¤ë¥¼ ì´ì¤‘ìœ¼ë¡œ êµ¬ì„±í•˜ì—¬ ê³ ì¶œë ¥ í”Œë¼ì¦ˆë§ˆ ìƒì„±"""

        data = {
            "prompt": prompt,
            "max_tokens": 500,
            "temperature": 0.7
        }
        
        response = requests.post(
            "https://api.cohere.ai/v1/generate",
            headers=headers,
            json=data,
            timeout=15
        )
        
        if response.status_code == 200:
            result = response.json()
            summary = result.get('generations', [{}])[0].get('text', '').strip()
            return summary
        else:
            return None
    except:
        return None

# ===== MULTI-LANGUAGE SEARCH =====
def perform_multilingual_search(category_config, category_name, tavily_client, history, max_results=3):
    all_results = []
    seen_urls = set()
    
    for lang_name, lang_code in LANGUAGES.items():
        if len(all_results) >= MAX_PER_CATEGORY:
            break
            
        query = category_config["queries"].get(lang_code, category_config["queries"]["en"])
        
        try:
            results = tavily_client.search(
                query=query,
                search_depth="advanced",
                max_results=max_results,
                include_raw_content=True
            )
            
            for res in results.get('results', []):
                if len(all_results) >= MAX_PER_CATEGORY:
                    break
                    
                url = res.get('url')
                title = res.get('title', 'No title')
                content = res.get('content', '')
                
                if url in seen_urls or url in history["articles"]:
                    continue
                
                if len(content) < 100:
                    continue
                
                if is_duplicate(title, content, history):
                    continue
                
                seen_urls.add(url)
                all_results.append({
                    "url": url,
                    "title": title,
                    "content": content,
                    "language": lang_name,
                    "raw_content": res.get('raw_content', content)[:1000]
                })
        except:
            pass
    
    return all_results

# ===== MAIN UI =====
st.markdown("""
<div class="header-container">
    <h1>ğŸ›¡ï¸ Samsung ìœ ëŸ½ ì¡°ë‹¬ ì„¼í„° ì „ëµ ì¸í…”ë¦¬ì „ìŠ¤</h1>
    <p>ì „ëµ ì •ë³´ ëŒ€ì‹œë³´ë“œ â€¢ ì¼ì¼ ìë™í™” ë¦¬í¬íŠ¸</p>
</div>
""", unsafe_allow_html=True)

# Sidebar
st.sidebar.header("âš™ï¸ ì„¤ì •")
tavily_key = st.sidebar.text_input("Tavily API Key", type="password", help="Tavily API í‚¤ ì…ë ¥")
cohere_key = st.sidebar.text_input("Cohere API Key", type="password", help="Cohere API í‚¤ ì…ë ¥ (ìš”ì•½ìš©)")

history = load_history()
st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ“Š íˆìŠ¤í† ë¦¬ ìƒíƒœ")

col1, col2 = st.sidebar.columns(2)
col1.metric("ì¶”ì ëœ ê¸°ì‚¬", len(history["articles"]))
col2.metric("ê³ ìœ  ì½˜í…ì¸ ", len(history["content_hashes"]))

if history.get("last_updated"):
    last_update = datetime.fromisoformat(history["last_updated"])
    st.sidebar.caption(f"ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {last_update.strftime('%Y-%m-%d %H:%M')}")

if st.sidebar.button("ğŸ—‘ï¸ íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”", use_container_width=True):
    if os.path.exists(HISTORY_FILE):
        os.remove(HISTORY_FILE)
    st.rerun()

# ===== MAIN BUTTON =====
st.markdown("---")

col_button1, col_button2 = st.columns([2, 1])
with col_button1:
    run_report = st.button("ğŸš€ ì „ëµ ì¸í…”ë¦¬ì „ìŠ¤ ë¦¬í¬íŠ¸ ìƒì„±", use_container_width=True, key="run_report")

with col_button2:
    if st.button("â„¹ï¸ ì†Œê°œ", use_container_width=True):
        st.info("Samsung ì „ëµ ì¡°ë‹¬ ì—ì´ì „íŠ¸ - ìœ ëŸ½ ë‰´ìŠ¤ë¥¼ 10ê°œ ì–¸ì–´ë¡œ ìŠ¤ìº”í•©ë‹ˆë‹¤.")

# ===== RUN REPORT =====
if run_report:
    if not tavily_key:
        st.error("âŒ Tavily API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    elif not cohere_key:
        st.error("âŒ Cohere API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    else:
        client = TavilyClient(api_key=tavily_key)
        history = load_history()
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        all_articles = []
        articles_by_category = {}
        
        for idx, (cat_name, cat_config) in enumerate(CATEGORIES.items()):
            status_text.text(f"ğŸ” {cat_name} ê²€ìƒ‰ ì¤‘...")
            
            results = perform_multilingual_search(cat_config, cat_name, client, history, max_results=2)
            
            if results:
                articles_by_category[cat_name] = results
                all_articles.extend(results)
            
            progress_bar.progress((idx + 1) / len(CATEGORIES))
        
        all_articles = all_articles[:MAX_TOTAL_ARTICLES]
        
        progress_bar.empty()
        status_text.empty()
        
        # Stats
        st.markdown("---")
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("ğŸ” ìƒˆ ê¸°ì‚¬", len(all_articles))
        col2.metric("ğŸ“‚ ì¹´í…Œê³ ë¦¬", len(articles_by_category))
        col3.metric("ğŸ’¾ ì´ ê¸°ì‚¬", len(history["articles"]))
        col4.metric("ğŸŒ ì–¸ì–´", len(LANGUAGES))
        
        st.markdown("---")
        
        if all_articles:
            article_count = 0
            
            for cat_name, articles in articles_by_category.items():
                if article_count >= MAX_TOTAL_ARTICLES:
                    break
                
                cat_emoji = CATEGORIES[cat_name]["emoji"]
                st.markdown(f"### {cat_emoji} {cat_name}")
                st.markdown(f"*{len(articles)}ê°œì˜ ìƒˆë¡œìš´ ê¸°ì‚¬*")
                
                for article in articles:
                    if article_count >= MAX_TOTAL_ARTICLES:
                        break
                    
                    article_count += 1
                    
                    with st.spinner(f"ğŸ“ ê¸°ì‚¬ {article_count} ìš”ì•½ ì¤‘..."):
                        summary = summarize_with_groq(article['title'], article['content'], cohere_key)
                        
                        try:
                            title_kr = translate_to_korean_cached(article['title'])
                        except:
                            title_kr = article['title']
                    
                    # Display
                    st.markdown(f"#### ğŸ“° {article_count}. {title_kr}")
                    col_lang, col_cat = st.columns([1, 1])
                    with col_lang:
                        st.caption(f"ğŸŒ {article['language']}")
                    with col_cat:
                        st.caption(f"ğŸ“‚ {cat_name}")
                    
                    # Summary
                    if summary:
                        st.markdown(summary)
                    else:
                        st.warning("ìš”ì•½ ìƒì„± ì‹¤íŒ¨")
                    
                    # Buttons
                    col1, col2, col3 = st.columns([2, 1, 1])
                    with col1:
                        st.markdown(f"[ğŸ“– ì „ì²´ ê¸°ì‚¬ ì½ê¸°]({article['url']})")
                    with col2:
                        if st.button("âœ… ì½ìŒ", key=f"read_{article['url']}", use_container_width=True):
                            add_to_history(article['url'], article['title'], article['content'], cat_name, article['language'])
                            st.success("ì™„ë£Œ!")
                    with col3:
                        if st.button("ğŸ”— ë§í¬", key=f"copy_{article['url']}", use_container_width=True):
                            st.code(article['url'])
                    
                    st.divider()
            
            st.markdown("### ğŸ“Š ë¦¬í¬íŠ¸ ì™„ë£Œ")
            col1, col2, col3 = st.columns(3)
            col1.metric("âœ… ìƒíƒœ", "ì™„ë£Œ")
            col2.metric("ğŸ†• ê¸°ì‚¬", len(all_articles))
            col3.metric("ğŸ“ˆ DB", len(history["articles"]))
        else:
            st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
